{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_York_City_Taxi_Fare_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOe7rc8j5HKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6181d9f8-b75f-4025-f8a2-071f2d86a1ba"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G8Y-6FqLrLR"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm-6ouPr7zR_"
      },
      "source": [
        "test_dataset =  pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/test.csv')\n",
        "train_dataset =  pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/train.csv', nrows= 20_000_000)\n",
        "print(test_dataset.shape)\n",
        "print(train_dataset.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn4ywvIhj1Vc"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JsrAMXftueY"
      },
      "source": [
        "## Handling missing values and outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGIULAxoafsE"
      },
      "source": [
        "# There are only 139 NaN in training data and no missing values in test data, so we are dropping rows from training data\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset.isnull().any(1)].index, axis = 0)\n",
        "\n",
        "# There are 832 negative values in \"fare_amount\" column and we are removing those\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['fare_amount'] < 0].index, axis=0)\n",
        "\n",
        "# In training dataset there are 15 cases where \"passenger_count\" is 208 which doesn't look right, so removing, in test there is none\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['passenger_count']==208].index, axis = 0)\n",
        "\n",
        "# As latitude ranges between -90 and +90, so we are removing values outside this range(outliers)\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['pickup_latitude'] < -90].index, axis=0)\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['pickup_latitude'] > 90].index, axis=0)\n",
        "\n",
        "# Like latitude, longitude also ranges between -180 and +180, so removing the rest\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['pickup_longitude'] < -180].index, axis=0)\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['pickup_longitude'] > 180].index, axis=0)\n",
        "\n",
        "# Same operations for \"dropoff_latitude\" and \"dropoff_longitude\"\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['dropoff_latitude'] < -90].index, axis=0)\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['dropoff_latitude'] > 90].index, axis=0)\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['dropoff_longitude'] < -180].index, axis=0)\n",
        "train_dataset = train_dataset.drop(train_dataset[train_dataset['dropoff_longitude'] > 180].index, axis=0)\n",
        "\n",
        "# Change the \"key\" and \"pickup_datetime\" column datatype to date-time from object\n",
        "train_dataset['key'] = pd.to_datetime(train_dataset['key'], infer_datetime_format=True)\n",
        "train_dataset['pickup_datetime']  = pd.to_datetime(train_dataset['pickup_datetime'], infer_datetime_format=True)\n",
        "test_dataset['key'] = pd.to_datetime(test_dataset['key'], infer_datetime_format=True)\n",
        "test_dataset['pickup_datetime']  = pd.to_datetime(test_dataset['pickup_datetime'], infer_datetime_format=True)\n",
        "\n",
        "print(\"Final shape for training and test data after data cleaning: {} and {}\".format(train_dataset.shape, test_dataset.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as6bNPl9yq--"
      },
      "source": [
        "## Save the cleaned data to load/use later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGMmfgbdyPCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5456e03-d979-4aeb-c839-05d5edede95d"
      },
      "source": [
        "#train_dataset.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/train_dataset_20M_after_cleaning.csv')\n",
        "#test_dataset.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/test_dataset_20M_after_cleaning.csv')\n",
        "\n",
        "test_dataset =  pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/test_dataset_20M_after_cleaning.csv', index_col=[0])\n",
        "train_dataset =  pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/train_dataset_20M_after_cleaning.csv', nrows= 20_000_000, index_col=[0])\n",
        "print(train_dataset.shape, test_dataset.shape)\n",
        "\n",
        "train_dataset['key'] = pd.to_datetime(train_dataset['key'], infer_datetime_format=True)\n",
        "train_dataset['pickup_datetime']  = pd.to_datetime(train_dataset['pickup_datetime'], infer_datetime_format=True)\n",
        "test_dataset['key'] = pd.to_datetime(test_dataset['key'], infer_datetime_format=True)\n",
        "test_dataset['pickup_datetime']  = pd.to_datetime(test_dataset['pickup_datetime'], infer_datetime_format=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19998006, 8) (9914, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7imRs0TuAUw"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "1. Extract \"Year\", \"Month\", \"Date\", \"Day of Week\" and \"Hour\" columns from \"pickup_datetime\"\n",
        "\n",
        "2. Create a \"Distance\" column from pickup and dropoff, latitude and longitude"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uKVeb-Kbo67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a276ad-43c9-4d1f-d0c5-dcbe7a6f63fd"
      },
      "source": [
        "# Extract \"Year\", \"Month\", \"Date\", \"Day of Week\" and \"Hour\" columns from \"pickup_datetime\"\n",
        "train_dataset['Year'] = train_dataset['pickup_datetime'].dt.year\n",
        "train_dataset['Month'] = train_dataset['pickup_datetime'].dt.month\n",
        "train_dataset['Date'] = train_dataset['pickup_datetime'].dt.day\n",
        "train_dataset['Day of Week'] = train_dataset['pickup_datetime'].dt.dayofweek\n",
        "train_dataset['Hour'] = train_dataset['pickup_datetime'].dt.hour\n",
        "\n",
        "test_dataset['Year'] = test_dataset['pickup_datetime'].dt.year\n",
        "test_dataset['Month'] = test_dataset['pickup_datetime'].dt.month\n",
        "test_dataset['Date'] = test_dataset['pickup_datetime'].dt.day\n",
        "test_dataset['Day of Week'] = test_dataset['pickup_datetime'].dt.dayofweek\n",
        "test_dataset['Hour'] = test_dataset['pickup_datetime'].dt.hour\n",
        "\n",
        "# Remove \"key\" and \"pickup_datetime\" as we have captured this info above\n",
        "train_dataset = train_dataset.drop(['key','pickup_datetime'], axis = 1)\n",
        "test_dataset = test_dataset.drop(['key','pickup_datetime'], axis = 1)\n",
        "\n",
        "# Creating a \"Distance\" column is a logical choice as it will help to determine the fare\n",
        "# We will use Haversine distance to calculate distance from pickup and dropoff, latitude and longitude\n",
        "def calculate_distance(lat1, lon1, lat2, lon2, dataframe):\n",
        "\n",
        "    # Convert degrees to radians\n",
        "    lon1_radians = np.radians(dataframe[lon1])\n",
        "    lon2_radians = np.radians(dataframe[lon2])\n",
        "    lat1_radians = np.radians(dataframe[lat1])\n",
        "    lat2_radians = np.radians(dataframe[lat2])\n",
        "\n",
        "    # Haversine formula\n",
        "    dlon = lon2_radians - lon1_radians\n",
        "    dlat = lat2_radians - lat1_radians\n",
        "    a = np.sin(dlat / 2)**2 + np.cos(lat1_radians) * np.cos(lat2_radians) * np.sin(dlon / 2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "    # calculate the result\n",
        "    dataframe[\"Distance\"]= (c * 6371)\n",
        "\n",
        "calculate_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', train_dataset)\n",
        "calculate_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', test_dataset)\n",
        "\n",
        "print(train_dataset.head())\n",
        "print(test_dataset.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  Year  Month  Date  Day of Week  Hour  Distance\n",
            "0          4.5        -73.844311        40.721319         -73.841610         40.712278                1  2009      6    15            0    17  1.030764\n",
            "1         16.9        -74.016048        40.711303         -73.979268         40.782004                1  2010      1     5            1    16  8.450134\n",
            "2          5.7        -73.982738        40.761270         -73.991242         40.750562                2  2011      8    18            3     0  1.389525\n",
            "3          7.7        -73.987130        40.733143         -73.991567         40.758092                1  2012      4    21            5     4  2.799270\n",
            "4          5.3        -73.968095        40.768008         -73.956655         40.783762                1  2010      3     9            1     7  1.999157\n",
            "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  Year  Month  Date  Day of Week  Hour  Distance\n",
            "0        -73.973320        40.763805         -73.981430         40.743835                1  2015      1    27            1    13  2.323260\n",
            "1        -73.986862        40.719383         -73.998886         40.739201                1  2015      1    27            1    13  2.425353\n",
            "2        -73.982524        40.751260         -73.979654         40.746139                1  2011     10     8            5    11  0.618628\n",
            "3        -73.981160        40.767807         -73.990448         40.751635                1  2012     12     1            5    21  1.961033\n",
            "4        -73.966046        40.789775         -73.988565         40.744427                1  2012     12     1            5    21  5.387301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEtnmqE_zhqz"
      },
      "source": [
        "## Seperate training labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPZMFPpXzhEs"
      },
      "source": [
        "X_train = train_dataset.iloc[:, train_dataset.columns != 'fare_amount']\n",
        "y_train = train_dataset['fare_amount'].values\n",
        "X_test = test_dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6mnXCz6GuN"
      },
      "source": [
        "# Train and test different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3GyOBBHw0Yu"
      },
      "source": [
        "## Using simple Linear Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "blg5LRKqwyqN",
        "outputId": "9f6d198f-84a0-4591-a096-033cb44407fd"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialise, train and test the model\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_lr_1.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-27 13:08:24.0000002</td>\n",
              "      <td>12.779795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-27 13:08:24.0000003</td>\n",
              "      <td>12.777705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-10-08 11:53:44.0000002</td>\n",
              "      <td>11.239468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-12-01 21:12:12.0000002</td>\n",
              "      <td>11.804325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-12-01 21:12:12.0000003</td>\n",
              "      <td>11.808343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-12-01 21:12:12.0000005</td>\n",
              "      <td>11.805898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-10-06 12:10:20.0000001</td>\n",
              "      <td>11.197601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-10-06 12:10:20.0000003</td>\n",
              "      <td>11.208312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-10-06 12:10:20.0000002</td>\n",
              "      <td>11.196773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014-02-18 15:22:20.0000002</td>\n",
              "      <td>12.172163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           key  fare_amount\n",
              "0  2015-01-27 13:08:24.0000002    12.779795\n",
              "1  2015-01-27 13:08:24.0000003    12.777705\n",
              "2  2011-10-08 11:53:44.0000002    11.239468\n",
              "3  2012-12-01 21:12:12.0000002    11.804325\n",
              "4  2012-12-01 21:12:12.0000003    11.808343\n",
              "5  2012-12-01 21:12:12.0000005    11.805898\n",
              "6  2011-10-06 12:10:20.0000001    11.197601\n",
              "7  2011-10-06 12:10:20.0000003    11.208312\n",
              "8  2011-10-06 12:10:20.0000002    11.196773\n",
              "9  2014-02-18 15:22:20.0000002    12.172163"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUTJSfbO2EoU"
      },
      "source": [
        "## Using Polynomial Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoXPl_wk2EZ9"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Initialise, train and test the model\n",
        "polynomial_features = PolynomialFeatures(degree = 3)\n",
        "X_train_poly = polynomial_features.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train_poly, y_train)\n",
        "y_pred = regressor.predict(polynomial_features.fit_transform(X_test))\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_plr_2.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNkUsyGR8XKT"
      },
      "source": [
        "## Using Support Vector Regressor(SVR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPtfSsSF8W7j"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Initialise, train and test the model\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_svr_1.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6rEh45v3jnn"
      },
      "source": [
        "## Using Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "fI_VILXx4M8P",
        "outputId": "6b62a4dd-d32b-4f96-edbd-75fa481657aa"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialise, train and test the model\n",
        "regressor_1 = RandomForestRegressor(n_estimators = 200, random_state = 42, max_samples = 0.05, max_features = 0.6)\n",
        "regressor_1.fit(X_train, y_train)\n",
        "y_pred = regressor_1.predict(X_test)\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_rf_3.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-27 13:08:24.0000002</td>\n",
              "      <td>10.51750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-27 13:08:24.0000003</td>\n",
              "      <td>10.34500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-10-08 11:53:44.0000002</td>\n",
              "      <td>4.44200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-12-01 21:12:12.0000002</td>\n",
              "      <td>8.79850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-12-01 21:12:12.0000003</td>\n",
              "      <td>16.04700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-12-01 21:12:12.0000005</td>\n",
              "      <td>11.15200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-10-06 12:10:20.0000001</td>\n",
              "      <td>5.03050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-10-06 12:10:20.0000003</td>\n",
              "      <td>48.98905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-10-06 12:10:20.0000002</td>\n",
              "      <td>11.81605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014-02-18 15:22:20.0000002</td>\n",
              "      <td>6.21000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           key  fare_amount\n",
              "0  2015-01-27 13:08:24.0000002     10.51750\n",
              "1  2015-01-27 13:08:24.0000003     10.34500\n",
              "2  2011-10-08 11:53:44.0000002      4.44200\n",
              "3  2012-12-01 21:12:12.0000002      8.79850\n",
              "4  2012-12-01 21:12:12.0000003     16.04700\n",
              "5  2012-12-01 21:12:12.0000005     11.15200\n",
              "6  2011-10-06 12:10:20.0000001      5.03050\n",
              "7  2011-10-06 12:10:20.0000003     48.98905\n",
              "8  2011-10-06 12:10:20.0000002     11.81605\n",
              "9  2014-02-18 15:22:20.0000002      6.21000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlZ-PjAi52Ic"
      },
      "source": [
        "## Using XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "rh38sLoJ6R1X",
        "outputId": "6b04a222-a8b9-457c-a8c2-a3c661e88fe4"
      },
      "source": [
        "import xgboost\n",
        "\n",
        "# Initialise, train and test the model\n",
        "regressor_2 = xgboost.XGBRegressor(objective = \"reg:squarederror\",\n",
        "                  n_estimators = 100, \n",
        "                  seed = 42,\n",
        "                  eta = 0.1,\n",
        "                  eval_metric = \"rmse\",\n",
        "                  max_depth = 7,\n",
        "                  verbose = False)\n",
        "regressor_2.fit(X_train, y_train, verbose = False)\n",
        "y_pred = regressor_2.predict(X_test, num_iteration = regressor_2.best_iteration_)\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_xgboost_2.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:32:09] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-27 13:08:24.0000002</td>\n",
              "      <td>10.249455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-27 13:08:24.0000003</td>\n",
              "      <td>10.932947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-10-08 11:53:44.0000002</td>\n",
              "      <td>4.674202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-12-01 21:12:12.0000002</td>\n",
              "      <td>8.953639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-12-01 21:12:12.0000003</td>\n",
              "      <td>15.907702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-12-01 21:12:12.0000005</td>\n",
              "      <td>11.079843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-10-06 12:10:20.0000001</td>\n",
              "      <td>5.152694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-10-06 12:10:20.0000003</td>\n",
              "      <td>48.422676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-10-06 12:10:20.0000002</td>\n",
              "      <td>11.859878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014-02-18 15:22:20.0000002</td>\n",
              "      <td>6.789435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           key  fare_amount\n",
              "0  2015-01-27 13:08:24.0000002    10.249455\n",
              "1  2015-01-27 13:08:24.0000003    10.932947\n",
              "2  2011-10-08 11:53:44.0000002     4.674202\n",
              "3  2012-12-01 21:12:12.0000002     8.953639\n",
              "4  2012-12-01 21:12:12.0000003    15.907702\n",
              "5  2012-12-01 21:12:12.0000005    11.079843\n",
              "6  2011-10-06 12:10:20.0000001     5.152694\n",
              "7  2011-10-06 12:10:20.0000003    48.422676\n",
              "8  2011-10-06 12:10:20.0000002    11.859878\n",
              "9  2014-02-18 15:22:20.0000002     6.789435"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU9--92iBZL9"
      },
      "source": [
        "## Using LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "Xrw36wwhBdmM",
        "outputId": "9ab0220f-2c82-4f23-a323-c10159c5ca90"
      },
      "source": [
        "import lightgbm\n",
        "\n",
        "# Initialise, train and test the model\n",
        "regressor_3 = lightgbm.LGBMRegressor(boosting_type = \"gbdt\", \n",
        "                                     learning_rate = 0.1, \n",
        "                                     n_estimators = 200, \n",
        "                                     objective = \"regression\", \n",
        "                                     subsample = 0.1,\n",
        "                                     random_state = 42,\n",
        "                                     metric = \"rmse\",\n",
        "                                     verbose = 0)\n",
        "regressor_3.fit(X_train, y_train, verbose = False)\n",
        "y_pred = regressor_3.predict(X_test)\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_lgbm_3.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-27 13:08:24.0000002</td>\n",
              "      <td>10.690266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-27 13:08:24.0000003</td>\n",
              "      <td>11.026318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-10-08 11:53:44.0000002</td>\n",
              "      <td>4.953806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-12-01 21:12:12.0000002</td>\n",
              "      <td>8.370679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-12-01 21:12:12.0000003</td>\n",
              "      <td>15.599452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-12-01 21:12:12.0000005</td>\n",
              "      <td>10.860681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-10-06 12:10:20.0000001</td>\n",
              "      <td>5.247845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-10-06 12:10:20.0000003</td>\n",
              "      <td>49.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-10-06 12:10:20.0000002</td>\n",
              "      <td>11.316202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014-02-18 15:22:20.0000002</td>\n",
              "      <td>6.671705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           key  fare_amount\n",
              "0  2015-01-27 13:08:24.0000002    10.690266\n",
              "1  2015-01-27 13:08:24.0000003    11.026318\n",
              "2  2011-10-08 11:53:44.0000002     4.953806\n",
              "3  2012-12-01 21:12:12.0000002     8.370679\n",
              "4  2012-12-01 21:12:12.0000003    15.599452\n",
              "5  2012-12-01 21:12:12.0000005    10.860681\n",
              "6  2011-10-06 12:10:20.0000001     5.247845\n",
              "7  2011-10-06 12:10:20.0000003    49.530000\n",
              "8  2011-10-06 12:10:20.0000002    11.316202\n",
              "9  2014-02-18 15:22:20.0000002     6.671705"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8n8WoYpAhqr"
      },
      "source": [
        "## Using Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9WfqaZPyAhhL",
        "outputId": "f90fa615-6b3c-4ed1-dce1-92b613a73e49"
      },
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "print(\"Tensorflow version: {}\\n\".format(tf.__version__))\n",
        "\n",
        "# Define the model\n",
        "regressor=Sequential()\n",
        "regressor.add(Dense(units = X_train.shape[1], activation='relu', input_dim = X_train.shape[1]))\n",
        "regressor.add(Dense(units = 20, activation='relu'))\n",
        "regressor.add(Dense(units = 20, activation='relu'))\n",
        "regressor.add(Dense(units=1))\n",
        "print(regressor.summary())\n",
        "\n",
        "# Specify other hyper-parameters then train and test\n",
        "regressor.compile(optimizer = \"Adam\", loss='mean_squared_error', metrics=['accuracy'])\n",
        "regressor.fit(X_train, y_train, validation_split=0.0005, batch_size=10000, epochs=50, shuffle=True)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Save the results\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/sample_submission.csv')\n",
        "submission['fare_amount'] = y_pred\n",
        "submission.to_csv('/content/drive/MyDrive/Newyork taxi fair prediction challenge/submission_nn_1.csv', index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.7.0\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 11)                132       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 20)                240       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813\n",
            "Trainable params: 813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "1999/1999 [==============================] - 13s 6ms/step - loss: 2591.2427 - accuracy: 1.0006e-06 - val_loss: 83.6455 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 226.1571 - accuracy: 6.0036e-07 - val_loss: 36.6066 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 220.7051 - accuracy: 7.5045e-07 - val_loss: 36.5113 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 220.7190 - accuracy: 7.5045e-07 - val_loss: 36.4327 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.6382 - accuracy: 6.0036e-07 - val_loss: 36.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 220.6678 - accuracy: 6.5039e-07 - val_loss: 35.7111 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 219.1078 - accuracy: 6.0036e-07 - val_loss: 35.5091 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 220.1203 - accuracy: 7.5045e-07 - val_loss: 35.1089 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 220.3939 - accuracy: 7.0042e-07 - val_loss: 34.9627 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 219.3669 - accuracy: 6.5039e-07 - val_loss: 34.9818 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.5582 - accuracy: 6.5039e-07 - val_loss: 34.9605 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.9757 - accuracy: 7.5045e-07 - val_loss: 35.1961 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.9041 - accuracy: 7.5045e-07 - val_loss: 34.9259 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.8845 - accuracy: 6.0036e-07 - val_loss: 35.0243 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.4394 - accuracy: 8.5051e-07 - val_loss: 35.1038 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 219.6516 - accuracy: 6.5039e-07 - val_loss: 35.4042 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.8374 - accuracy: 6.0036e-07 - val_loss: 34.9228 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 219.3188 - accuracy: 7.0042e-07 - val_loss: 34.9274 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.5278 - accuracy: 6.0036e-07 - val_loss: 34.8417 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 219.2160 - accuracy: 6.5039e-07 - val_loss: 34.9145 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.2913 - accuracy: 6.5039e-07 - val_loss: 35.0774 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.5682 - accuracy: 6.5039e-07 - val_loss: 34.7257 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 219.2316 - accuracy: 7.5045e-07 - val_loss: 34.9274 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.9985 - accuracy: 6.0036e-07 - val_loss: 34.9206 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.5695 - accuracy: 7.0042e-07 - val_loss: 35.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.1907 - accuracy: 6.0036e-07 - val_loss: 34.9689 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.8957 - accuracy: 6.0036e-07 - val_loss: 35.1229 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.7769 - accuracy: 6.5039e-07 - val_loss: 34.9567 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 219.1229 - accuracy: 7.0042e-07 - val_loss: 35.1335 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.7987 - accuracy: 6.5039e-07 - val_loss: 34.9709 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.8848 - accuracy: 6.0036e-07 - val_loss: 35.1930 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.4469 - accuracy: 6.0036e-07 - val_loss: 34.9573 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.8360 - accuracy: 6.0036e-07 - val_loss: 35.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.2732 - accuracy: 6.5039e-07 - val_loss: 35.0923 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.8044 - accuracy: 6.0036e-07 - val_loss: 34.8080 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.4728 - accuracy: 6.5039e-07 - val_loss: 34.8891 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.9004 - accuracy: 6.0036e-07 - val_loss: 35.3188 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.6315 - accuracy: 7.5045e-07 - val_loss: 35.0587 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.2235 - accuracy: 6.0036e-07 - val_loss: 34.4146 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.5189 - accuracy: 6.5039e-07 - val_loss: 34.4685 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.6934 - accuracy: 6.0036e-07 - val_loss: 34.6543 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.6166 - accuracy: 6.0036e-07 - val_loss: 34.6804 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.1575 - accuracy: 6.0036e-07 - val_loss: 34.8591 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.4339 - accuracy: 6.0036e-07 - val_loss: 34.5680 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 217.8840 - accuracy: 6.5039e-07 - val_loss: 34.0511 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 217.9235 - accuracy: 6.0036e-07 - val_loss: 33.9284 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 218.3418 - accuracy: 6.0036e-07 - val_loss: 34.6684 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.4916 - accuracy: 6.0036e-07 - val_loss: 34.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "1999/1999 [==============================] - 12s 6ms/step - loss: 218.1125 - accuracy: 6.0036e-07 - val_loss: 34.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "1999/1999 [==============================] - 11s 6ms/step - loss: 217.9977 - accuracy: 6.5039e-07 - val_loss: 34.4073 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-27 13:08:24.0000002</td>\n",
              "      <td>8.517562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-27 13:08:24.0000003</td>\n",
              "      <td>8.704256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-10-08 11:53:44.0000002</td>\n",
              "      <td>6.043541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-12-01 21:12:12.0000002</td>\n",
              "      <td>8.083719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-12-01 21:12:12.0000003</td>\n",
              "      <td>15.750600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-12-01 21:12:12.0000005</td>\n",
              "      <td>10.362946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-10-06 12:10:20.0000001</td>\n",
              "      <td>6.165036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-10-06 12:10:20.0000003</td>\n",
              "      <td>54.224850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-10-06 12:10:20.0000002</td>\n",
              "      <td>11.427979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014-02-18 15:22:20.0000002</td>\n",
              "      <td>6.350249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           key  fare_amount\n",
              "0  2015-01-27 13:08:24.0000002     8.517562\n",
              "1  2015-01-27 13:08:24.0000003     8.704256\n",
              "2  2011-10-08 11:53:44.0000002     6.043541\n",
              "3  2012-12-01 21:12:12.0000002     8.083719\n",
              "4  2012-12-01 21:12:12.0000003    15.750600\n",
              "5  2012-12-01 21:12:12.0000005    10.362946\n",
              "6  2011-10-06 12:10:20.0000001     6.165036\n",
              "7  2011-10-06 12:10:20.0000003    54.224850\n",
              "8  2011-10-06 12:10:20.0000002    11.427979\n",
              "9  2014-02-18 15:22:20.0000002     6.350249"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}